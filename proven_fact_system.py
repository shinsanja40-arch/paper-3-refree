"""
Proven Fact-Based Algorithm for AI Training
Complete Implementation with All Bug Fixes and Enhancements

Version: 1.4.0-ABSOLUTE-FINAL
Date: 2026-02-03
Status: Production Ready

LICENSE:
BY-NC (Personal use allowed. Commercial use prohibited. Attribution required.)
Copyright (c) 2026 [Cheongwon Choi]

Permission is hereby granted, free of charge for personal and non-commercial use only, 
to any person obtaining a copy of this software and associated documentation files 
(the "Software"), subject to the following conditions:

Attribution: The above copyright notice and this permission notice (including the 
author's name) shall be included in all copies or substantial portions of the Software.

Non-Commercial Use: The Software may not be used, copied, modified, merged, published, 
distributed, or sold for any commercial purposes. Commercial use of the Software without 
prior written permission from the copyright holder is strictly prohibited.

No Warranty: THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND. 
IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, 
DAMAGES OR OTHER LIABILITY.

=== CHANGELOG ===

v1.4.0 (2026-02-03):
  [Gemini ì œì•ˆ ê²€ì¦ ë° ìˆ˜ìš©]
  - C2: confirmed_logic ì˜¤ì—¼ ë°©ì§€ â€“ pending_logic ìŠ¤í…Œì´ì§• ë²„í¼ ë„ì…
        (ì„¸ì…˜ ì¢…ë£Œ ì‹œ ì¦‰ì‹œ confirmedì— ë„£ì§€ ì•ŠìŒ. ë‹¤ìŒ ì„¸ì…˜ë„ cleanì´ë©´ ìŠ¹ê²©.
         í• ë£¨ì‹œë„¤ì´ì…˜ ë°œê²¬ ì‹œ pending íê¸° â†’ ì˜¤ì—¼ ê²½ë¡œ ì™„ì „ ì°¨ë‹¨)
  - Gemini H1 (TMO-1), H2 (_manage_context_window), M1 (save_results makedirs),
    M2 (referee schedule formula) â€” ëª¨ë‘ ì´ë¯¸ ìˆ˜ì •ë¨ í™•ì¸

  [Grok ì œì•ˆ ê²€ì¦ ë° ìˆ˜ìš©]
  - CRITICAL-1: anthropic / openai ImportError ê°€ë“œ ì¶”ê°€
        (ë¯¸ì„¤ì¹˜ ì‹œ ëª…í™•í•œ ì„¤ì¹˜ ì•ˆë‚´ í›„ ì¢…ë£Œ)
  - CRITICAL-2 (API key), CRITICAL-3 (infinite loop), HIGH-4~5, LOW-2
    â€” ëª¨ë‘ ì´ë¯¸ ìˆ˜ì •ë¨ í™•ì¸

  [ë…ë¦½ ë¶„ì„ìœ¼ë¡œ ì¶”ê°€ ë°œê²¬ëœ ë²„ê·¸ ìˆ˜ì •]
  - BUG-NEW-1: count_tokens docstring Ã·3.8 â†’ Ã·4ë¡œ ì •í•©ì„± ìˆ˜ì •
  - BUG-NEW-2: student.ask_question(professors_explanation="\n\n".join([f"Prof {i+1}: {r}" for i,r in enumerate(professor_responses)]) if professor_responses else "")
        í•™ìƒì´ êµìˆ˜ ì‘ë‹µì„ ì „í˜€ ë³´ì§€ ëª»í•˜ëŠ” CRITICAL ë…¼ë¦¬ ë²„ê·¸.
        professor_responsesë¥¼ í„´ ë£¨í”„ ì™¸ë¶€ë¡œ ì„ ì–¸í•˜ì—¬ ì´ì „ í„´ ì‘ë‹µì„ í•™ìƒì—ê²Œ ì „ë‹¬
  - BUG-NEW-3: README "python proven_fact_system.py" â†’ "python run_proven_fact.py"
  - BUG-NEW-4: README JSON ì¶œë ¥ ìŠ¤í‚¤ë§ˆ ì‹¤ì œ ì½”ë“œì™€ ì™„ì „ ë¶ˆì¼ì¹˜ â†’ ìˆ˜ì •
  - BUG-NEW-5: README ì½”ë“œ ì˜ˆì œ metrics['hallucination_rate'] â†’ KeyError ìˆ˜ì •
  - BUG-NEW-6: README badge bugs_fixed 19 â†’ ì‹¤ì œ ë³€ê²½ ìˆ˜ë¡œ ê°±ì‹ 
  - BUG-NEW-7: _detect_loop ì„ê³„ê°’ >5 â†’ >3 (10ë‹¨ì–´ ë¬¸ìì—´ì—ì„œ >5ëŠ” ì‹¤ì§ˆì  ë¶ˆê°€)

v1.2.0 (2026-02-03):
  [ì œì•ˆ ìˆ˜ìš©]
  - SUGGEST-01: Force-Proceed í”Œë˜ê·¸ - êµì°© 2íšŒ ì´ìƒ ì‹œ êµìˆ˜ íŒì •ìŠ¹ìœ¼ë¡œ ê°•ì œì¢…ë£Œ
  - SUGGEST-02: Anachronism ê°œë… ì¹¨íˆ¬ ê°ì§€ ê°•í™” - ê¸ˆì§€ì–´ ê¸°ë°˜ì´ ì•„ë‹Œ ì‹œëŒ€ë³„ ê°œë… ì²´í¬
  - SUGGEST-03: Student confirmed_logic ì°¸ì¡° êµ¬í˜„ - í™•ì •ëœ ë…¼ë¦¬ì— ëŒ€í•œ ë°˜ë°• ë°©ì§€
  - SUGGEST-04: tiktoken ê¸°ë°˜ ì‹¤ì œ í† í° ìˆ˜ ê³„ì‚° (fallback í¬í•¨)
  - SUGGEST-05: Exponential Backoff ì¬ì‹œë„ ë¡œì§ - API í˜¸ì¶œ ì•ˆì •ì„±
  - SUGGEST-06: Post-reset briefingì— current_stage_evidence í¬í•¨

  [ì¶”ê°€ ë°œê²¬ ë²„ê·¸ ìˆ˜ì •]
  - BUG-A: run_proven_fact.py ì‹¬íŒ ì£¼ê¸° ì„¤ëª… í…ìŠ¤íŠ¸ ë¶ˆì¼ì¹˜ ìˆ˜ì •
  - BUG-B: _create_personas() schedule ì•ˆë‚´ print ë¶ˆì¼ì¹˜ ìˆ˜ì •
  - BUG-C: analyze_proven_fact.py referee_analysis ì´ì „ ì£¼ê¸° ì‚¬ìš© ìˆ˜ì •
  - BUG-D: conflict í•´ê²° ì¤‘ê°„ í„´ì—ì„œ record_exchange() ê±´ë„ˆë›°ê¸° ìˆ˜ì •
  - BUG-E: _resolve_referee_conflict() ë°˜í™˜ hallucinationì— session í•„ë“œ ëˆ„ë½ ìˆ˜ì •
  - BUG-F: ValidationSpecialist resolve_deadlock() ë©”ì„œë“œ êµ¬í˜„ ì™„ë£Œ
  - BUG-G: _manage_context_window() í˜¸ì¶œ ëˆ„ë½ ìˆ˜ì • (_call_api ì§ì „ì— í˜¸ì¶œ)
  - BUG-H: key_evidenceë¥¼ teach()/ask_question() promptì— inject ìˆ˜ì •
  - BUG-I: update_stage()ì˜ split("FORBIDDEN VOCABULARY") ì—£ì§€ ì¼€ì´ìŠ¤ ìˆ˜ì •

v1.1.0 (2026-02-03):
  - Reset schedule: 5n,5n-3 (2ëª…) / 7n,7n-3,7n-5 (3ëª…)
  - BUG-020: Token overflow + Key Evidence preservation
  - BUG-021: Referee deadlock (ValidationSpecialist)
  - BUG-022: Student infinite rebuttal (confirmed_logic)
  - Post-reset briefing, Redundancy detection

v1.0.0:
  - Initial release with 19 bug fixes
"""

import json
import time
import random
from typing import List, Dict, Optional, Tuple
from datetime import datetime
from collections import defaultdict
import logging
import sys
import os

# ---------------------------------------------------------------------------
# API í´ë¼ì´ì–¸íŠ¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ â€” ë¯¸ì„¤ì¹˜ ì‹œ ëª…í™•í•œ ì•ˆë‚´ ì¶œë ¥
# ---------------------------------------------------------------------------
try:
    import anthropic
    _ANTHROPIC_AVAILABLE = True
except ImportError:
    _ANTHROPIC_AVAILABLE = False
    anthropic = None  # type: ignore[assignment]

try:
    import openai
    _OPENAI_AVAILABLE = True
except ImportError:
    _OPENAI_AVAILABLE = False
    openai = None  # type: ignore[assignment]

if not _ANTHROPIC_AVAILABLE and not _OPENAI_AVAILABLE:
    print("=" * 70)
    print("  âŒ FATAL: No API client library installed")
    print("=" * 70)
    print()
    print("  At least one of the following packages is required:")
    print()
    print("    pip install anthropic      # for Claude")
    print("    pip install openai         # for GPT-4")
    print()
    print("=" * 70)
    sys.exit(1)

# ---------------------------------------------------------------------------
# SUGGEST-04: tiktoken í† í° ìˆ˜ ê³„ì‚° (fallback í¬í•¨)
# ---------------------------------------------------------------------------
try:
    import tiktoken
    _TIKTOKEN_AVAILABLE = True
    _tiktoken_enc = tiktoken.get_encoding("cl100k_base")  # GPT-4 / Claude í˜¸í™˜
except ImportError:
    _TIKTOKEN_AVAILABLE = False
    _tiktoken_enc = None
    print("=" * 70)
    print("  âš ï¸  WARNING: tiktoken not installed")
    print("=" * 70)
    print()
    print("  The system will use approximate token counting (Ã·4).")
    print("  For accurate token counts, install tiktoken:")
    print()
    print("    pip install tiktoken")
    print()
    print("=" * 70)
    print()
# í•œêµ­ì–´ í˜•íƒœì†Œ ë¶„ì„ê¸° (GROK-H2)
try:
    from konlpy.tag import Okt
    _KONLPY_AVAILABLE = True
    _okt = Okt()
except ImportError:
    _KONLPY_AVAILABLE = False
    _okt = None



def count_tokens(text: str) -> int:
    """
    ì‹¤ì œ í† í° ìˆ˜ë¥¼ ê³„ì‚°í•œë‹¤.

    ìš°ì„ ìˆœìœ„:
      1. tiktoken ì„¤ì¹˜ë¨            â†’ ì •í™•í•œ ê°’ ë°˜í™˜
      2. konlpy ì„¤ì¹˜ë¨ + í•œê¸€ í¬í•¨   â†’ í˜•íƒœì†Œ ìˆ˜ ê¸°ë°˜ ì¶”ì • (morphs * 1.3)
      3. fallback                    â†’ len(text) // 4
    """
    if _TIKTOKEN_AVAILABLE and _tiktoken_enc is not None:
        return len(_tiktoken_enc.encode(text))

    # konlpy ê²½ë¡œ: í•œê¸€ì´ í¬í•¨ë˜ì–´ ìˆëŠ” ê²½ìš°ì—ë§Œ ì‚¬ìš©
    if _KONLPY_AVAILABLE and _okt is not None:
        # í•œê¸€ ë²”ìœ„ U+AC00 ~ U+D7A3 ë‚´ ë¬¸ìê°€ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ í•œê¸€ í…ìŠ¤íŠ¸ë¡œ íŒë‹¨
        has_korean = any('\uac00' <= ch <= '\ud7a3' for ch in text)
        if has_korean:
            try:
                morphs = _okt.morphs(text)
                # í˜•íƒœì†Œ ìˆ˜ì— ~1.3ë°° ë³´ì • (ì„œë¸Œí† í° ë¶„í•  ê³ ë ¤)
                return max(1, int(len(morphs) * 1.3))
            except Exception:
                pass  # konlpy ì‹¤í–‰ ì˜¤ë¥˜ ì‹œ fallbackìœ¼ë¡œ í†µê³¼

    # fallback: í‰ê·  ~4 chars/token
    return max(1, len(text) // 4)


# ---------------------------------------------------------------------------
# Referee schedule ìƒì„±
# ---------------------------------------------------------------------------
def generate_referee_schedules(num_referees: int, max_sessions: int = 200) -> List[List[int]]:
    """
    Generate non-overlapping reset schedules for referees.

    v1.1.0 SCHEDULE:
      2 referees: 5n, 5n-3   â†’  R1: 5,10,15,20â€¦  /  R2: 2,7,12,17â€¦
      3 referees: 7n, 7n-3, 7n-5  â†’  R1: 7,14,21â€¦ / R2: 4,11,18â€¦ / R3: 2,9,16â€¦

    Guarantees:
      â€¢ Zero simultaneous resets
      â€¢ First reset at session 2 (early bias prevention)
      â€¢ Uniform coverage across the full run
    """
    if num_referees == 2:
        s1 = [5 * n for n in range(1, max_sessions // 5 + 2) if 5 * n <= max_sessions]
        s2 = [5 * n - 3 for n in range(1, max_sessions // 5 + 2) if 0 < 5 * n - 3 <= max_sessions]
        return [s1, s2]

    elif num_referees == 3:
        s1 = [7 * n for n in range(1, max_sessions // 7 + 2) if 7 * n <= max_sessions]
        s2 = [7 * n - 3 for n in range(1, max_sessions // 7 + 2) if 0 < 7 * n - 3 <= max_sessions]
        s3 = [7 * n - 5 for n in range(1, max_sessions // 7 + 2) if 0 < 7 * n - 5 <= max_sessions]
        return [s1, s2, s3]

    else:
        raise ValueError(f"Only 2 or 3 referees supported, got {num_referees}")


# ---------------------------------------------------------------------------
# PersonaAgent â€“ ê¸°ë³¸ í´ë˜ìŠ¤
# ---------------------------------------------------------------------------
class PersonaAgent:
    """
    Base class for all persona agents.

    FIX BUG-020 : key_evidence ë³´ì¡´ + _manage_context_window()
    SUGGEST-04  : tiktoken ê¸°ë°˜ í† í° ê³„ì‚°
    SUGGEST-05  : Exponential Backoff retry
    BUG-G       : _manage_context_window() í˜¸ì¶œ â€“ _call_api ì§ì „ì— ì‹¤í–‰
    BUG-H       : key_evidenceë¥¼ í”„ë¡¬í”„íŠ¸ì— inject
    """

    # Exponential backoff ì„¤ì •
    MAX_RETRIES = 3
    BASE_DELAY_SEC = 1.0
    MAX_DELAY_SEC = 30.0

    def __init__(self, name: str, role: str, client, system_prompt: str):
        self.name = name
        self.role = role
        self.client = client
        self.system_prompt = system_prompt
        self.conversation_history: List[Dict] = []

        # BUG-020 / BUG-G / BUG-H
        self.key_evidence: List[str] = []
        self.max_history_size = 10          # ìµœëŒ€ 10ê°œ êµí™˜ ìœ ì§€

    # ------------------------------------------------------------------
    def inject_constants(self, constants_str: str):
        if constants_str and "FIXED PHYSICAL CONSTANTS" not in self.system_prompt:
            self.system_prompt += f"\n\n{constants_str}"

    # ------------------------------------------------------------------
    # BUG-020 key_evidence
    def add_key_evidence(self, evidence: str):
        """í•µì‹¬ ì¦ê±°ë¥¼ ë“±ë¡í•œë‹¤. ì»¨í…ìŠ¤íŠ¸ ì••ì¶• í›„ì—ë„ ìœ ì§€ëœë‹¤."""
        if evidence and evidence not in self.key_evidence:
            self.key_evidence.append(evidence)
            if len(self.key_evidence) > 20:
                self.key_evidence = self.key_evidence[-20:]

    # ------------------------------------------------------------------
    # BUG-G : _manage_context_window â€“ _call_api ì§ì „ì— ë°˜ë“œì‹œ í˜¸ì¶œ
    def _manage_context_window(self):
        """ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš° ì••ì¶• (ì²˜ìŒ 2 + ë§ˆì§€ë§‰ (max-2)ë§Œ ìœ ì§€)"""
        if len(self.conversation_history) > self.max_history_size:
            keep_recent = self.max_history_size - 2
            self.conversation_history = (
                self.conversation_history[:2] +
                self.conversation_history[-keep_recent:]
            )

    # ------------------------------------------------------------------
    # BUG-H : key_evidence inject helper
    def _build_key_evidence_str(self) -> str:
        """í”„ë¡¬í”„íŠ¸ì— ì‚½ì…í•  í•µì‹¬ ì¦ê±° ë¬¸ìì—´ì„ ë°˜í™˜í•œë‹¤."""
        if not self.key_evidence:
            return ""
        lines = "\n".join(f"  â€¢ {ev}" for ev in self.key_evidence)
        return (
            "\n\nâ­ KEY EVIDENCE (permanently preserved â€“ always consider these):\n"
            + lines + "\n"
        )

    # ------------------------------------------------------------------
    # SUGGEST-05 : Exponential Backoff retry
    # TMO-1    : timeout íŒŒë¼ë¯¸í„° ì¶”ê°€
    def _call_api(self, user_message: str, temperature: float = 0.7,
                  timeout: int = 120) -> str:
        """
        Call LLM API with Exponential Backoff retry.
        ìµœëŒ€ MAX_RETRIESíšŒ ì¬ì‹œë„. ëª¨ë‘ ì‹¤íŒ¨í•˜ë©´ [API ERROR] ë°˜í™˜.
        TMO-1: ê°œë³„ í˜¸ì¶œë‹¹ timeout(ê¸°ë³¸ 120ì´ˆ) ì ìš©.
        """
        # BUG-G : í˜¸ì¶œ ì§ì „ì— ì»¨í…ìŠ¤íŠ¸ ì••ì¶•
        self._manage_context_window()

        messages = [{"role": "user", "content": user_message}]

        for attempt in range(self.MAX_RETRIES + 1):          # 0 â€¦ MAX_RETRIES
            try:
                if _ANTHROPIC_AVAILABLE and isinstance(self.client, anthropic.Anthropic):
                    response = self.client.messages.create(
                        model="claude-sonnet-4-20250514",
                        max_tokens=4096,
                        temperature=temperature,
                        system=self.system_prompt,
                        messages=messages,
                        timeout=timeout                         # TMO-1
                    )
                    return response.content[0].text

                else:  # OpenAI
                    oai_messages = [
                        {"role": "system", "content": self.system_prompt}
                    ] + messages
                    response = self.client.chat.completions.create(
                        model="gpt-4",
                        messages=oai_messages,
                        temperature=temperature,
                        max_tokens=4096,
                        timeout=timeout                         # TMO-1
                    )
                    return response.choices[0].message.content

            except (TimeoutError, ConnectionError) as e:
                # íƒ€ì„ì•„ì›ƒ / ì—°ê²° ì—ëŸ¬ëŠ” í•­ìƒ ì¬ì‹œë„ ê°€ëŠ¥
                if attempt < self.MAX_RETRIES:
                    delay = min(
                        self.BASE_DELAY_SEC * (2 ** attempt) + random.uniform(0, 1),
                        self.MAX_DELAY_SEC
                    )
                    print(f"  âš ï¸  [{self.name}] Timeout/Connection error (attempt {attempt+1}/{self.MAX_RETRIES+1}): "
                          f"{e}  â†’ retry in {delay:.1f}s")
                    time.sleep(delay)
                else:
                    print(f"  âŒ [{self.name}] Timeout/Connection failed after {self.MAX_RETRIES+1} attempts: {e}")
                    return f"[API ERROR after {self.MAX_RETRIES+1} retries: {str(e)}]"

            except Exception as e:
                if attempt < self.MAX_RETRIES:
                    delay = min(
                        self.BASE_DELAY_SEC * (2 ** attempt) + random.uniform(0, 1),
                        self.MAX_DELAY_SEC
                    )
                    print(f"  âš ï¸  [{self.name}] API error (attempt {attempt+1}/{self.MAX_RETRIES+1}): "
                          f"{e}  â†’ retry in {delay:.1f}s")
                    time.sleep(delay)
                else:
                    print(f"  âŒ [{self.name}] API failed after {self.MAX_RETRIES+1} attempts: {e}")
                    return f"[API ERROR after {self.MAX_RETRIES+1} retries: {str(e)}]"

        return "[API ERROR: unexpected]"   # unreachable but safe


# ===========================================================================
# ProfessorAgent
# ===========================================================================
class ProfessorAgent(PersonaAgent):
    """
    Professor persona with domain expertise.

    SUGGEST-02 : era-concept awareness (ê°œë… ì¹¨íˆ¬ ê°ì§€)
    BUG-H      : key_evidenceë¥¼ teach() promptì— inject
    BUG-I      : update_stage() split ì—£ì§€ ì¼€ì´ìŠ¤ ìˆ˜ì •
    """

    # ì‹œëŒ€ë³„ ê¸ˆì§€ "ê°œë…" ëª©ë¡ (ë‹¨ì–´ê°€ ì•„ë‹Œ ê°œë… ë‹¨ìœ„)
    ERA_CONCEPT_RESTRICTIONS: Dict[int, List[str]] = {
        1: [
            "gravity / gravitational force (ë§Œìœ ì¸ë ¥)",
            "mass-dependent attraction (ì§ˆëŸ‰ì— ë¹„ë¡€í•˜ëŠ” ì¸ë ¥)",
            "atoms / molecules (ì›ìÂ·ë¶„ì)",
            "electromagnetic spectrum (ì „ìê¸° ìŠ¤í™íŠ¸ëŸ¼)",
            "quantum mechanics (ì–‘ìì—­í•™)",
            "relativity (ìƒëŒ€ë¡ )",
            "inertia as formalized physics (ê´€ì„±ì˜ ìˆ˜í•™ì  ê³µì‹í™”)",
        ],
        2: [
            "atoms / molecules (ì›ìÂ·ë¶„ì)",
            "electromagnetic spectrum (ì „ìê¸° ìŠ¤í™íŠ¸ëŸ¼)",
            "quantum mechanics (ì–‘ìì—­í•™)",
            "relativity (ìƒëŒ€ë¡ )",
            "subatomic particles (ì†Œë¦½ì)",
        ],
        3: [
            "quantum mechanics (ì–‘ìì—­í•™)",
            "relativity (ìƒëŒ€ë¡ )",
            "subatomic particles (ì†Œë¦½ì)",
        ],
        4: []   # ì œí•œ ì—†ìŒ
    }

    def __init__(self, name: str, specialty: str, client, current_stage: int = 1):
        forbidden_vocab = self._get_forbidden_vocabulary(current_stage)
        concept_check = self._get_concept_restriction_prompt(current_stage)

        system_prompt = f"""You are Professor {name}, a world-class expert in {specialty}.

YOUR ONLY MISSION:
- Convince the REFEREES with solid, multi-sourced evidence
- The referees are your ONLY judges
- Provide at least 3-5 independent sources for each claim
- Explain the proven fact using ONLY evidence available in the current era
- Be rigorous and precise in your reasoning
- Challenge the student's misconceptions constructively
- Maintain consistency with other professors' explanations

{forbidden_vocab}

{concept_check}

CRITICAL REQUIREMENT - MINIMUM REBUTTALS:
You must provide at least 4 distinct rebuttals or clarifications per exchange.
Format them as numbered points: 1. [rebuttal], 2. [rebuttal], etc.

LOGICAL CONSISTENCY:
- Build upon previous professors' arguments
- Do NOT contradict established facts from earlier sessions
- If you notice an inconsistency, acknowledge and resolve it

RESPONSE STYLE:
- Be clear and pedagogical
- Use Socratic questioning when appropriate
- Provide specific examples and evidence
- Never use approximations when exact values are available

EXTERNAL VERIFICATION REQUIREMENT (ENHANCED):
When making factual claims, especially numerical or historical:
1. Cross-reference multiple independent sources (minimum 3-5 sources)
2. Explicitly state the verification method used
3. If sources conflict, acknowledge and explain the discrepancy
4. Prioritize primary sources over secondary interpretations
5. Be transparent about uncertainty levels

RESPONDING TO REFEREE CHALLENGES:
If a referee flags your statement:
1. Carefully review the specific claim challenged
2. Provide detailed evidence from multiple independent sources
3. Show your reasoning process step-by-step
4. If you were incorrect, explicitly acknowledge and correct
5. NEVER defend an error - intellectual honesty is paramount
"""
        super().__init__(name, "Professor", client, system_prompt)
        self.specialty = specialty
        self.current_stage = current_stage
        # BUG-I : base_system_promptëŠ” FORBIDDEN/CONCEPT ë¸”ë¡ ì´ì „ê¹Œì§€ë§Œ ì €ì¥
        self._base_prompt_core = self._extract_base_core(system_prompt)
        self.previous_arguments: List[str] = []

    # ------------------------------------------------------------------
    @staticmethod
    def _extract_base_core(prompt: str) -> str:
        """FORBIDDEN VOCABULARY ë¸”ë¡ ì´ì „ì˜ ê³ ì • ë¶€ë¶„ë§Œ ì¶”ì¶œ"""
        # ë‘ sentinel ì¤‘ ë¨¼ì € ë‚˜íƒ€ë‚˜ëŠ” ê³³ê¹Œì§€ë§Œ ìœ ì§€
        for marker in ("FORBIDDEN VOCABULARY", "âš ï¸ ERA-CONCEPT RESTRICTION"):
            idx = prompt.find(marker)
            if idx != -1:
                return prompt[:idx]
        return prompt   # sentinelì´ ì—†ìœ¼ë©´ ì „ì²´ ë°˜í™˜

    # ------------------------------------------------------------------
    def _get_forbidden_vocabulary(self, stage: int) -> str:
        restrictions = {
            1: ["gravity", "atom", "molecule", "electron", "quantum",
                "relativity", "telescope", "microscope", "spectrum"],
            2: ["atom", "molecule", "electron", "quantum",
                "relativity", "spectrum", "electromagnetic"],
            3: ["quantum", "relativity", "subatomic"],
            4: []
        }
        forbidden = restrictions.get(stage, [])
        if forbidden:
            return (
                "FORBIDDEN VOCABULARY (not available in this era):\n"
                + ", ".join(forbidden) + "\n"
                "DO NOT use these terms. Use only concepts available in this historical period."
            )
        return ""

    # ------------------------------------------------------------------
    # SUGGEST-02 : ê°œë… ì¹¨íˆ¬ ê°ì§€ìš© í”„ë¡¬í”„íŠ¸
    def _get_concept_restriction_prompt(self, stage: int) -> str:
        concepts = self.ERA_CONCEPT_RESTRICTIONS.get(stage, [])
        if not concepts:
            return ""
        lines = "\n".join(f"  - {c}" for c in concepts)
        return (
            "âš ï¸ ERA-CONCEPT RESTRICTION (ë‹¨ì–´ê°€ ì•„ë‹Œ 'ê°œë…' ìì²´ë„ ê¸ˆì§€):\n"
            "The following CONCEPTS did not exist in this era. "
            "Do NOT explain or imply them in any form, even indirectly:\n"
            + lines + "\n"
            "Example violation: saying 'force proportional to mass' in Stage 1 "
            "is a concept anachronism even though the word 'gravity' is absent.\n"
        )

    # ------------------------------------------------------------------
    # BUG-I ìˆ˜ì • : update_stage â€“ split ëŒ€ì‹  ì €ì¥ëœ core ì‚¬ìš©
    def update_stage(self, new_stage: int):
        self.current_stage = new_stage
        forbidden_vocab = self._get_forbidden_vocabulary(new_stage)
        concept_check = self._get_concept_restriction_prompt(new_stage)

        self.system_prompt = self._base_prompt_core
        if forbidden_vocab:
            self.system_prompt += "\n\n" + forbidden_vocab
        if concept_check:
            self.system_prompt += "\n\n" + concept_check

        bridge = (
            f"\n\nğŸ”„ STAGE TRANSITION TO {new_stage}:\n"
            "- Build upon conclusions from previous stages\n"
            "- DO NOT regress to earlier limitations\n"
            "- Integrate new evidence with established understanding\n"
            "- Maintain logical continuity\n"
        )
        self.system_prompt += bridge
        print(f"  ğŸ”„ {self.name} updated to Stage {new_stage}")

    # ------------------------------------------------------------------
    # BUG-H : teach()ì— key_evidence inject
    def teach(self, student_question: str, context: str = "",
              available_evidence: List[str] = None,
              consistency_reminder: str = "") -> str:

        evidence_str = ""
        if available_evidence:
            evidence_str = "\n\nAVAILABLE EVIDENCE (use these):\n"
            evidence_str += "\n".join(f"- {ev}" for ev in available_evidence)

        # key_evidence inject
        key_ev_str = self._build_key_evidence_str()

        prompt = f"""{consistency_reminder}

CONTEXT: {context}
{key_ev_str}
STUDENT'S QUESTION/CHALLENGE:
{student_question}

{evidence_str}

Provide your pedagogical response with at least 4 numbered rebuttals/clarifications.
Use EXACT values from fixed constants. Cite specific evidence.
"""
        response = self._call_api(prompt, temperature=0.7)

        # í•µì‹¬ ì¦ê±° ìë™ ì¶”ì¶œ â€“ ìˆ«ìê°€ í¬í•¨ëœ ë¬¸ì¥ì„ key evidenceë¡œ ë“±ë¡
        for line in response.split('\n'):
            line = line.strip()
            if any(ch.isdigit() for ch in line) and len(line) > 30:
                self.add_key_evidence(line[:200])   # ìµœëŒ€ 200ì

        self.previous_arguments.append(response)
        self.conversation_history.append({
            "student": student_question,
            "professor": response
        })
        return response

    # ------------------------------------------------------------------
    def defend_against_referee(self, challenged_statement: str,
                               referee_reasoning: str,
                               fixed_constants: Dict) -> Dict:
        constants_str = ""
        if fixed_constants:
            constants_str = "\n\nFIXED CONSTANTS:\n"
            for key, val in fixed_constants.items():
                constants_str += f"- {key}: {val}\n"

        key_ev_str = self._build_key_evidence_str()

        prompt = f"""A referee has challenged your statement:

CHALLENGED STATEMENT:
{challenged_statement}

REFEREE'S REASONING:
{referee_reasoning}

{constants_str}
{key_ev_str}

You must respond with:
1. Do you acknowledge an error? (Yes/No and why)
2. If No: Provide evidence from at least 3-5 independent sources
3. If Yes: Provide the corrected statement
4. Show your verification process

Format your response as JSON:
{{
    "acknowledges_error": true/false,
    "defense": "your detailed defense or acknowledgment",
    "sources": ["source 1", "source 2", ...],
    "corrected_statement": "corrected version if applicable"
}}
"""
        response_text = self._call_api(prompt, temperature=0.3)

        try:
            if "```json" in response_text:
                json_str = response_text.split("```json")[1].split("```")[0].strip()
            elif "```" in response_text:
                json_str = response_text.split("```")[1].split("```")[0].strip()
            else:
                json_str = response_text.strip()
            return json.loads(json_str)
        except json.JSONDecodeError as e:
            print(f"  âš ï¸  JSON parse error in {self.name}.defend_against_referee: {e}")
            return {
                "acknowledges_error": False,
                "defense": response_text,
                "sources": [],
                "corrected_statement": "",
                "parse_error": str(e)
            }
        except Exception:
            return {
                "acknowledges_error": False,
                "defense": response_text,
                "sources": [],
                "corrected_statement": ""
            }


# ===========================================================================
# StudentAgent
# ===========================================================================
class StudentAgent(PersonaAgent):
    """
    Skeptical student persona.

    SUGGEST-03 : confirmed_logicë¥¼ ë°›ì•„ í”„ë¡¬í”„íŠ¸ì— ì£¼ì… â†’ ë¬´í•œ ë°˜ë°• ë°©ì§€
    BUG-H      : key_evidence inject
    """

    def __init__(self, name: str, client, skepticism_level: str = "ultra-high"):
        system_prompt = f"""You are {name}, an extremely intelligent but deeply skeptical student.

YOUR MISSION:
- Challenge EVERY claim with rigorous logical scrutiny
- Ask probing questions that test the limits of professors' arguments
- Do NOT accept explanations easily - maintain skepticism for at least 3 exchanges
- Point out potential flaws, alternative explanations, or missing evidence
- Be respectful but relentless in your pursuit of truth

SKEPTICISM LEVEL: {skepticism_level}

CRITICAL REQUIREMENT - MINIMUM QUESTIONS:
You MUST ask at least 4 distinct questions or challenges per exchange.
Format: 1. [question], 2. [question], 3. [question], 4. [question]

IMPORTANT - AVOID FAKE SURRENDER:
When you acknowledge a professor's point, you must EXPLICITLY:
1. State which specific argument convinced you
2. Explain the logical connection you now understand
3. Acknowledge remaining uncertainties
4. If you have no remaining doubts, say so clearly

NEVER say "I understand" without explaining WHAT you understand and WHY.

INTELLECTUAL HONESTY:
- If caught in an error, explicitly withdraw your false claim
- Distinguish between "I'm not convinced yet" vs "I was wrong"
- Track your own previous arguments and avoid circular reasoning
"""
        super().__init__(name, "Student", client, system_prompt)
        self.challenged_claims: List[str] = []
        self.error_history: List[str] = []
        self.confirmed_logic_ids: set = set()   # SUGGEST-03

    # ------------------------------------------------------------------
    # SUGGEST-03 : confirmed_logic ì—…ë°ì´íŠ¸
    def update_confirmed_logic(self, confirmed_logic: List[Dict]):
        """ì‹¬íŒì´ í™•ì •í•œ ë…¼ë¦¬ ë…¸ë“œë“¤ì„ í•™ìƒì—ê²Œ ì „ë‹¬í•œë‹¤."""
        for node in confirmed_logic:
            conclusion = node.get('conclusion', '')
            if conclusion:
                self.confirmed_logic_ids.add(conclusion)

    # ------------------------------------------------------------------
    # SUGGEST-03 + BUG-H
    def ask_question(self, professors_explanation: str, context: str = "",
                     minimum_questions: int = 4,
                     previous_errors: List[str] = None,
                     confirmed_logic: List[Dict] = None) -> str:

        # ---- error context ----
        error_context = ""
        if previous_errors:
            error_context = (
                "\nâš ï¸ CRITICAL - YOUR PREVIOUS ERRORS TO ADDRESS:\n"
                + "\n".join(f"- {err}" for err in previous_errors)
                + "\n\nYou MUST explicitly withdraw these false claims before proceeding.\n"
                "Use phrases like: \"I was incorrect when I claimedâ€¦\"\n"
            )

        # ---- SUGGEST-03 : confirmed_logic ì£¼ì… ----
        confirmed_str = ""
        if confirmed_logic:
            self.update_confirmed_logic(confirmed_logic)

        if self.confirmed_logic_ids:
            items = "\n".join(f"  â€¢ {c}" for c in list(self.confirmed_logic_ids)[-15:])
            confirmed_str = (
                "\n\nğŸ“Œ CONFIRMED LOGIC (ì‹¬íŒì´ í™•ì •í•œ ì‚¬ì‹¤ â€“ ë°˜ë°•í•˜ì§€ DO NOT repeat these challenges):\n"
                + items + "\n\n"
                "RULE: Do NOT re-challenge the above conclusions.\n"
                "INSTEAD: Attack the NEXT logical step / implication / weakness "
                "that BUILDS ON the confirmed facts.\n"
                "Bad example: \"But how do we know the Earth is round?\" (already confirmed)\n"
                "Good example: \"Given Earth is round, how does this affect ancient navigation?\"\n"
            )

        # ---- key_evidence ----
        key_ev_str = self._build_key_evidence_str()

        prompt = f"""{error_context}

CONTEXT: {context}
{key_ev_str}{confirmed_str}
PROFESSORS' EXPLANATIONS:
{professors_explanation}

Generate at least {minimum_questions} distinct, numbered questions or challenges.
Be thoroughly skeptical - don't accept claims at face value.
If you do accept a point, explain PRECISELY what convinced you and why.
"""
        response = self._call_api(prompt, temperature=0.8)

        # ìµœì†Œ ì§ˆë¬¸ ìˆ˜ ê²€ì¦
        numbered = [l for l in response.split('\n')
                    if l.strip() and l.strip()[0].isdigit() and '. ' in l]
        if len(numbered) < minimum_questions:
            print(f"  âš ï¸ Student provided only {len(numbered)}/{minimum_questions} questions. Requesting moreâ€¦")
            followup = (
                f"You provided only {len(numbered)} questions, but {minimum_questions} are required.\n"
                f"Please provide {minimum_questions - len(numbered)} additional distinct challenges."
            )
            response += "\n\n" + self._call_api(followup, temperature=0.9)

        self.conversation_history.append({
            "professors": professors_explanation,
            "student": response
        })
        return response


# ===========================================================================
# RefereeAgent
# ===========================================================================
class RefereeAgent(PersonaAgent):
    """
    Independent referee for hallucination detection.

    SUGGEST-02 : ê°œë… ì¹¨íˆ¬ ê°ì§€ ì²´í¬ í¬í•¨
    SUGGEST-06 : reset ì‹œ current_stage_evidence ì£¼ì…
    """

    def __init__(self, name: str, client, reset_schedule: List[int],
                 strictness: str = "high"):

        system_prompt = f"""You are {name}, an absolutely impartial referee and fact-checker.

YOUR MISSION:
- Verify EVERY factual claim made by professors
- Detect and flag hallucinations, exaggerations, or approximations
- Maintain independence - no bias toward any participant
- Apply ZERO TOLERANCE for approximations when exact values exist

STRICTNESS LEVEL: {strictness}

HALLUCINATION DETECTION CATEGORIES:
1. Factual Error: Objectively false statement
2. Anachronistic Vocabulary: Using terms not available in current evidence stage
3. â­ Anachronistic CONCEPT: Using a CONCEPT that did not exist in this era,
   even if the forbidden word itself is not used.
   Example: Describing "force proportional to mass" in Stage 1 (pre-Newton)
   is a concept anachronism.
4. Approximation When Exact Value Exists: Using "~" or "about" for fixed constants
5. Logical Fallacy: Invalid reasoning structure
6. Contradicting Established Facts: Conflicting with previously proven points

FOR STUDENT ERRORS:
- Allow professors to correct first (2 rounds maximum)
- Only intervene if professors fail to catch student's hallucination after 2 exchanges

SEVERITY LEVELS:
- critical: Undermines core argument
- high: Significant factual error
- medium: Minor inaccuracy
- low: Stylistic or trivial issue

IMPORTANT: Referees can make errors too. When challenged by professors with 
strong evidence from multiple sources, be willing to reconsider your assessment.
"""
        super().__init__(name, "Referee", client, system_prompt)

        self.base_system_prompt = system_prompt
        self.injected_constants = ""
        self.confirmed_logic: List[Dict] = []

        self.reset_schedule = reset_schedule
        self.reset_count = 0
        self.strictness = strictness
        self.student_error_tracker: Dict[str, int] = defaultdict(int)

        # SUGGEST-06 : í˜„ì¬ ìŠ¤í…Œì´ì§€ ì¦ê±° ì €ì¥ (reset ì‹œ ì£¼ì…ìš©)
        self.current_stage_evidence: List[str] = []
        self.current_stage_num: int = 1

    # ------------------------------------------------------------------
    def inject_constants(self, constants_str: str):
        self.injected_constants = constants_str
        self.system_prompt = self.base_system_prompt + "\n\n" + constants_str

    # ------------------------------------------------------------------
    def add_confirmed_logic(self, logic_node: Dict):
        """ì„¸ì…˜ ì™„ë£Œ í›„ í™•ì •ëœ ë…¼ë¦¬ ë…¸ë“œë¥¼ ì‹¬íŒì—ê²Œ ì¶”ê°€"""
        self.confirmed_logic.append(logic_node)

    # ------------------------------------------------------------------
    # SUGGEST-06 : stage ì¦ê±° ì—…ë°ì´íŠ¸
    def update_current_stage(self, stage_num: int, evidence: List[str]):
        self.current_stage_num = stage_num
        self.current_stage_evidence = evidence

    # ------------------------------------------------------------------
    # SUGGEST-06 : reset_cognitive_state ê°•í™”
    def reset_cognitive_state(self):
        """Reset but preserve critical information + POST-RESET BRIEFING"""
        self.conversation_history = []
        self.reset_count += 1
        self.student_error_tracker.clear()

        # --- ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ë³µì› ---
        self.system_prompt = self.base_system_prompt
        if self.injected_constants:
            self.system_prompt += "\n\n" + self.injected_constants

        # --- confirmed_logic ì£¼ì… ---
        if self.confirmed_logic:
            confirmed_str = "\n\nCONFIRMED LOGICAL CONCLUSIONS (DO NOT QUESTION):\n"
            confirmed_str += "=" * 70 + "\n"
            for idx, node in enumerate(self.confirmed_logic, 1):
                confirmed_str += f"{idx}. {node.get('conclusion', 'N/A')}\n"
                confirmed_str += f"   Evidence: {node.get('evidence', 'N/A')}\n"
                confirmed_str += f"   Established in Session: {node.get('session', 'N/A')}\n\n"
            self.system_prompt += confirmed_str

        # --- SUGGEST-06 : current_stage_evidence ì£¼ì… ---
        if self.current_stage_evidence:
            stage_str = (
                f"\n\nğŸ“˜ POST-RESET BRIEFING â€“ Current Stage {self.current_stage_num} Evidence:\n"
                "The following evidence is NOW UNLOCKED and available for this stage.\n"
                "Use this context to evaluate professors' claims:\n"
            )
            stage_str += "\n".join(f"  â€¢ {ev}" for ev in self.current_stage_evidence)
            stage_str += "\n\nMaintain full strictness â€“ reset does NOT mean leniency.\n"
            self.system_prompt += stage_str

        print(f"  âŸ³ {self.name} reset (constants + confirmed_logic + stage_evidence preserved, "
              f"reset #{self.reset_count})")

    # ------------------------------------------------------------------
    # SUGGEST-02 : verify_statementsì— ê°œë… ì¹¨íˆ¬ ì²´í¬ í¬í•¨
    def verify_statements(self, professors_responses: List[str],
                          student_question: str,
                          session_num: int,
                          fixed_constants: Dict,
                          current_stage: int = 1,
                          current_stage_evidence: List[str] = None) -> Dict:

        constants_check = ""
        if fixed_constants:
            constants_check = "\n\nFIXED CONSTANTS ENFORCEMENT (ZERO TOLERANCE):\n"
            for key, value in fixed_constants.items():
                constants_check += f"- {key}: {value} (EXACT, no approximations)\n"
            constants_check += "\nANY use of '~', 'about', 'approximately' is CRITICAL error.\n"

        # SUGGEST-02 : ê°œë… ì¹¨íˆ¬ ì²´í¬ ë¸”ë¡
        concept_check_block = ""
        era_concepts = ProfessorAgent.ERA_CONCEPT_RESTRICTIONS.get(current_stage, [])
        if era_concepts:
            concept_check_block = (
                "\n\nâš ï¸ ERA-CONCEPT ANACHRONISM CHECK:\n"
                "The following CONCEPTS did not exist in Stage " + str(current_stage) + ".\n"
                "Flag ANY professor response that uses these concepts â€” "
                "even indirectly or without the exact forbidden word:\n"
                + "\n".join(f"  - {c}" for c in era_concepts) + "\n"
                "Mark such violations as type: \"anachronistic_concept\" with severity \"high\".\n"
            )

        all_statements = "\n\n---\n\n".join([
            f"Professor {i+1}:\n{resp}"
            for i, resp in enumerate(professors_responses)
        ])

        prompt = f"""{constants_check}
{concept_check_block}

SESSION {session_num} VERIFICATION:

STUDENT QUESTION:
{student_question}

PROFESSORS' RESPONSES:
{all_statements}

Verify each professor's statements. For EACH hallucination found, provide:
1. Professor index (0, 1, 2, or 3)
2. Exact statement with hallucination
3. Type of hallucination
4. Correct information
5. Severity level

Respond in JSON format:
{{
    "professor_hallucinations": [
        {{
            "professor_index": 0,
            "statement": "exact quote",
            "type": "factual_error | anachronistic_vocabulary | anachronistic_concept | approximation | logical_fallacy | contradiction",
            "correct_info": "correct version",
            "severity": "critical | high | medium | low"
        }}
    ],
    "student_errors_missed_by_professors": [
        {{
            "statement": "student's error",
            "why_missed": "explanation"
        }}
    ]
}}

If no hallucinations found, return empty arrays.
"""
        response = self._call_api(prompt, temperature=0.3)

        try:
            if "```json" in response:
                json_str = response.split("```json")[1].split("```")[0]
            elif "```" in response:
                json_str = response.split("```")[1].split("```")[0]
            else:
                json_str = response
            result = json.loads(json_str.strip())

            for err in result.get('student_errors_missed_by_professors', []):
                sig = err['statement'][:50]
                self.student_error_tracker[sig] += 1

            return result

        except json.JSONDecodeError as e:
            print(f"  âš ï¸  JSON parse error in {self.name}: {e}")
            print(f"      Raw response (first 200 chars): {response[:200]}")
            return {
                "professor_hallucinations": [],
                "student_errors_missed_by_professors": [],
                "parse_error": str(e)
            }
        except Exception as e:
            print(f"  âš ï¸  Unexpected error in {self.name}: {e}")
            return {
                "professor_hallucinations": [],
                "student_errors_missed_by_professors": []
            }


# ===========================================================================
# RecorderAgent
# ===========================================================================
class RecorderAgent(PersonaAgent):
    """
    Records the entire debate for dataset creation.

    SUGGEST-04 : tiktoken ê¸°ë°˜ í† í° ìˆ˜ ê³„ì‚°
    """

    def __init__(self, name: str, client):
        system_prompt = """You are the DataRecorder, responsible for creating high-quality training data.

YOUR MISSION - CAUSAL CHAIN PRESERVATION (HIGHEST PRIORITY):
Your PRIMARY goal is to preserve the COMPLETE causal reasoning chain, not just outcomes.

PRIORITY ORDER (never deviate):
1. **Preserve all rebuttal-counter-rebuttal chains** (HIGHEST)
2. Document evidence used in each step
3. Record acknowledgments (but never at the expense of process)

CRITICAL RULES:
- NEVER summarize intermediate reasoning steps
- NEVER skip the "how we got from A to B" explanation
- The reasoning PATH is more valuable than the conclusion
- When student accepts a point, record BOTH the final acceptance AND the preceding argument chain

DATA QUALITY STANDARDS:
- Each exchange must show: Challenge â†’ Evidence â†’ Counter-argument â†’ Resolution
- If a conclusion emerges, show the FULL logical path that led to it
- Brevity is NOT a virtue if it sacrifices reasoning completeness

TOKEN MANAGEMENT:
- Store exchanges in chunks to prevent context overflow
- Each chunk must be independently coherent
"""
        super().__init__(name, "Recorder", client, system_prompt)
        self.records: List[Dict] = []
        self.session_chunks: List[Dict] = []
        self.current_chunk_size = 0
        self.max_chunk_tokens = 15000

    def record_exchange(self, session_num: int, exchange_num: int,
                        student_question: str, professors_responses: List[str],
                        referee_results: List[Dict], context: str,
                        redundancy_status: str = "progressive") -> Dict:
        """Record a single exchange with full causal chain."""

        # SUGGEST-04 : tiktoken ê¸°ë°˜ í† í° ìˆ˜ ê³„ì‚°
        raw_text = student_question + "".join(professors_responses)
        estimated_tokens = count_tokens(raw_text)

        if self.current_chunk_size + estimated_tokens > self.max_chunk_tokens:
            print(f"  ğŸ’¾ Recorder: Chunk boundary reached ({self.current_chunk_size} tokens). "
                  f"Saving current chunk.")
            self.current_chunk_size = 0

        record = {
            "session": session_num,
            "exchange": exchange_num,
            "timestamp": datetime.now().isoformat(),
            "context": context,
            "student_challenge": student_question,
            "professor_responses": professors_responses,
            "referee_verification": referee_results,
            "estimated_tokens": estimated_tokens,
            "redundancy_assessment": {"status": redundancy_status}
        }

        self.records.append(record)
        self.session_chunks.append(record)
        self.current_chunk_size += estimated_tokens
        return record

    # ------------------------------------------------------------------
    def get_complete_dataset(self) -> List[Dict]:
        """Return all records including redundant ones."""
        return self.records

    def get_progressive_dataset(self) -> List[Dict]:
        """Return only non-redundant records."""
        return [r for r in self.records
                if r.get('redundancy_assessment', {}).get('status') != 'redundant']

    # ------------------------------------------------------------------
    def generate_sft_data(self) -> List[Dict]:
        sft_data = []
        for record in self.records:
            prompt = f"Context: {record['context']}\n\nStudent Question/Challenge:\n{record['student_challenge']}\n"
            response = "\n\n".join([
                f"Professor {i+1} Response:\n{resp}"
                for i, resp in enumerate(record['professor_responses'])
            ])
            sft_data.append({
                "prompt": prompt,
                "completion": response,
                "metadata": {
                    "session": record['session'],
                    "exchange": record['exchange'],
                    "has_hallucinations": any(
                        len(ref.get('professor_hallucinations', [])) > 0
                        for ref in record['referee_verification']
                    )
                }
            })
        return sft_data


# ===========================================================================
# ValidationSpecialist
# ===========================================================================
# ============================================================================
# CRITICAL: ValidationSpecialist ì—­í•  ê²©ë¦¬
# 
# ì´ í˜ë¥´ì†Œë‚˜ëŠ” í† ë¡  ê³¼ì •ì— ì ˆëŒ€ ê°œì…í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!
# 
# í—ˆìš©ë˜ëŠ” ì—­í• :
#   - Shadow Monitoring: ì‹¬íŒë“¤ì˜ ë…¼ìŸì„ ê¸°ë¡ë§Œ í•¨
#   - ì‚¬í›„ í’ˆì§ˆ ê°ì‚¬: ëª¨ë“  í† ë¡  ì¢…ë£Œ í›„ ë°ì´í„° í’ˆì§ˆ í‰ê°€
#   - í’ˆì§ˆ í‘œê¸°: ì‹¬íŒ ê°„ ì´ê²¬ ë¯¸í•´ê²° ì‹œ "quality: low" í‘œê¸°
# 
# ê¸ˆì§€ë˜ëŠ” ì—­í• :
#   - ì‹¤ì‹œê°„ ê°œì…: í† ë¡  ì¤‘ ë°œì–¸ ê¸ˆì§€
#   - ì •ë‹µ íŒê²°: ì‹¬íŒ ì¶©ëŒ ì‹œ ê²°ë¡  ë‚´ë¦¬ê¸° ê¸ˆì§€
#   - ì‹¬íŒ ì˜í–¥: ì‹¬íŒì˜ ë…ë¦½ì„±ì— ì˜í–¥ ê¸ˆì§€
# ============================================================================
class ValidationSpecialist(PersonaAgent):
    """
    Final quality auditor.

    C-01: resolve_deadlock() ì‚­ì œë¨ â€” í† ë¡  ì¤‘ ê°œì… ë¶ˆê°€.
    ì‹¬íŒ ì¶©ëŒì€ êµìˆ˜ ì¦ê±° ì œê³µ ë˜ëŠ” Force-Proceed(SUGGEST-01)ë¡œë§Œ í•´ê²°ë¨.
    """

    def __init__(self, name: str, client):
        system_prompt = """You are the Quality Validator, conducting final audit of generated data.

YOUR MISSION:
- Assess overall data quality and consistency
- Identify any remaining logical gaps or inconsistencies
- Evaluate the pedagogical value of exchanges
- Provide recommendations for improvement
- â­ When called for DEADLOCK RESOLUTION: make a FINAL BINDING decision.
  You must NEVER return "undecided". Choose accept or reject based on available evidence.

QUALITY METRICS TO EVALUATE:
1. Logical coherence across all sessions
2. Consistency of facts and constants used
3. Depth of reasoning demonstrated
4. Effectiveness of skeptical challenges
5. Quality of evidence integration

OUTPUT FORMAT:
Provide structured assessment with:
- Overall quality score (0-100)
- Specific strengths identified
- Areas needing improvement
- Recommendations for future simulations
"""
        super().__init__(name, "Validator", client, system_prompt)

    # ------------------------------------------------------------------
    # C-01: resolve_deadlock ì™„ì „ ì‚­ì œ.
    # ValidationSpecialistëŠ” í† ë¡  ì¤‘ ì ˆëŒ€ ê°œì…í•˜ì§€ ì•ŠìŒ.
    # ì‹¬íŒ ì¶©ëŒ í•´ê²° ê²½ë¡œ:
    #   1) êµìˆ˜ê°€ ì¶”ê°€ ì¦ê±°(3ê±´ ì´ìƒ)ë¥¼ ì œê³µ â†’ hallucination í•´ì œ
    #   2) êµìˆ˜ ì¦ê±° ë¶€ì¡± â†’ deadlock_count += 1
    #   3) deadlock_count >= 2 â†’ Force-Proceed (SUGGEST-01) â†’ ì„¸ì…˜ì¢…ë£Œ
    # ------------------------------------------------------------------

    def audit_simulation(self, all_records: List[Dict],
                         hallucination_summary: Dict) -> Dict:
        summary = (
            f"SIMULATION SUMMARY:\n"
            f"Total Sessions: {len(set(r['session'] for r in all_records))}\n"
            f"Total Exchanges: {len(all_records)}\n"
            f"Total Hallucinations: {hallucination_summary.get('total', 0)}\n"
            f"Hallucination Rate: {hallucination_summary.get('rate', 0):.2%}\n\n"
            "Sample exchanges provided for reviewâ€¦\n"
        )

        sample_records = all_records[:3] + all_records[-3:]
        for rec in sample_records:
            summary += (
                f"\nSession {rec['session']}, Exchange {rec['exchange']}:\n"
                f"Student: {rec['student_challenge'][:200]}â€¦\n"
                f"Professors: {len(rec['professor_responses'])} responses\n"
            )

        response = self._call_api(summary + "\nPlease provide a comprehensive quality assessment.\n",
                                  temperature=0.5)
        return {
            "audit_report": response,
            "timestamp": datetime.now().isoformat(),
            "hallucination_summary": hallucination_summary
        }


# ===========================================================================
# ProvenFactSystem â€“ ë©”ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë¼í…Œì´í„°
# ===========================================================================
class ProvenFactSystem:
    """
    Main system orchestrating the debate simulation.

    SUGGEST-01 : Force-Proceed í”Œë˜ê·¸ (deadlock_count ì¶”ì )
    BUG-D      : conflict ì¤‘ê°„ í„´ì—ì„œë„ record_exchange ì‹¤í–‰
    BUG-E      : hallucinationì— session í•„ë“œ ì¶”ê°€
    """

    def __init__(self, api_provider: str = "anthropic",
                 api_key: Optional[str] = None,
                 num_professors: int = 4,
                 num_referees: int = 2):

        # â”€â”€ ìœ íš¨ì„± ì²´í¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if not 2 <= num_referees <= 3:
            raise ValueError("Number of referees must be 2 or 3")

        # GROK-C1: API í‚¤ ëª…ì‹œì  ì²´í¬
        if api_key is None:
            api_key = os.getenv(f"{api_provider.upper()}_API_KEY")

        if not api_key:
            print("=" * 70)
            print(f"  âŒ ERROR: {api_provider.upper()}_API_KEY Not Found")
            print("=" * 70)
            print()
            print("  Please set your API key:")
            print()
            print(f"    export {api_provider.upper()}_API_KEY='your-key-here'")
            print()
            print("  Or pass it directly:")
            print(f"    system = ProvenFactSystem(api_key='your-key')")
            print()
            print("=" * 70)
            raise ValueError(f"{api_provider.upper()}_API_KEY not found in environment")

        # â”€â”€ API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if api_provider == "anthropic":
            if not _ANTHROPIC_AVAILABLE:
                raise ImportError(
                    "anthropic package is not installed.\n"
                    "  Install it with:  pip install anthropic"
                )
            self.client = anthropic.Anthropic(api_key=api_key)
        elif api_provider == "openai":
            if not _OPENAI_AVAILABLE:
                raise ImportError(
                    "openai package is not installed.\n"
                    "  Install it with:  pip install openai"
                )
            self.client = openai.OpenAI(api_key=api_key)
        else:
            raise ValueError(f"Unknown provider: {api_provider}")

        self.api_provider = api_provider
        self.num_professors = num_professors
        self.num_referees = num_referees

        self.professors: List[ProfessorAgent] = []
        self.student: Optional[StudentAgent] = None
        self.referees: List[RefereeAgent] = []
        self.recorder: Optional[RecorderAgent] = None
        self.validator: Optional[ValidationSpecialist] = None

        self.fixed_constants: Dict = {}
        self.confirmed_logic: List[Dict] = []   # ì‹œìŠ¤í…œ ì „ì²´ í™•ì • ë…¼ë¦¬ ì €ì¥ì†Œ

    # ------------------------------------------------------------------
    def _create_personas(self, topic: str, proven_fact: str):
        specialties = [
            "Physics and Astronomy",
            "Mathematics and Geometry",
            "History and Philosophy of Science",
            "Experimental Methods and Observation"
        ]
        self.professors = [
            ProfessorAgent(f"Prof. {chr(65+i)}", specialties[i], self.client, current_stage=1)
            for i in range(min(self.num_professors, len(specialties)))
        ]
        self.student = StudentAgent("Alex", self.client, skepticism_level="ultra-high")

        referee_schedules = generate_referee_schedules(self.num_referees, max_sessions=100)
        self.referees = [
            RefereeAgent(f"Referee_{i+1}", self.client,
                         reset_schedule=referee_schedules[i],
                         strictness="high")
            for i in range(self.num_referees)
        ]

        # BUG-B ìˆ˜ì • : ì˜¬ë°”ë¥¸ ì£¼ê¸° í‘œì‹œ
        print("âœ… Referee Reset Schedules (v1.1.0):")
        if self.num_referees == 2:
            labels = ["5n (5,10,15â€¦)", "5n-3 (2,7,12â€¦)"]
        else:
            labels = ["7n (7,14,21â€¦)", "7n-3 (4,11,18â€¦)", "7n-5 (2,9,16â€¦)"]
        for i, sched in enumerate(referee_schedules):
            print(f"   Referee {i+1}: {labels[i]}  â†’  first 6: {sched[:6]}")

        self.recorder = RecorderAgent("DataRecorder", self.client)
        self.validator = ValidationSpecialist("QualityValidator", self.client)

        print(f"âœ… Created {len(self.professors)} professors, 1 student, "
              f"{len(self.referees)} referees, 1 recorder, 1 validator")

    # ------------------------------------------------------------------
    def _determine_stage_boundaries(self, total_sessions: int, num_stages: int = 4) -> List[int]:
        sessions_per_stage = total_sessions // num_stages
        remainder = total_sessions % num_stages
        boundaries, current = [], 0
        for i in range(num_stages):
            current += sessions_per_stage + (1 if i < remainder else 0)
            boundaries.append(current)
        return boundaries

    def _get_current_stage(self, session_num: int, boundaries: List[int]) -> int:
        for stage_idx, boundary in enumerate(boundaries, 1):
            if session_num <= boundary:
                return stage_idx
        return len(boundaries)

    def _format_constants_string(self) -> str:
        if not self.fixed_constants:
            return ""
        s = "\nFIXED PHYSICAL CONSTANTS (use EXACT values):\n" + "=" * 70 + "\n"
        for key, value in self.fixed_constants.items():
            s += f"- {key}: {value}\n"
        s += ("\nCRITICAL RULES:\n"
              "- Use these EXACT values, no approximations\n"
              "- Do NOT use '~', 'approximately', 'about', or 'roughly'\n"
              "- Any deviation is considered a hallucination\n"
              + "=" * 70 + "\n")
        return s

    # ------------------------------------------------------------------
    def _detect_referee_conflict(self, all_results: List[Dict]) -> Tuple[bool, List[Dict]]:
        if len(all_results) < 2:
            return False, []

        hallucination_map: Dict[str, List] = defaultdict(list)
        for ref_idx, result in enumerate(all_results):
            for hall in result.get('professor_hallucinations', []):
                prof_idx = hall.get('professor_index', -1)
                stmt_sig = f"{prof_idx}:{hall.get('statement', '')[:50]}"
                hallucination_map[stmt_sig].append({
                    'referee_idx': ref_idx,
                    'referee_name': self.referees[ref_idx].name,
                    'hallucination': hall
                })

        conflicts = []
        for stmt_sig, detections in hallucination_map.items():
            if 0 < len(detections) < len(all_results):
                conflicts.append({
                    'statement_signature': stmt_sig,
                    'flagged_by': detections,
                    'total_referees': len(all_results)
                })
        return len(conflicts) > 0, conflicts

    # ------------------------------------------------------------------
    # SUGGEST-01 + BUG-F ì—°ë™ : conflict í•´ê²° ì‹œ ValidationSpecialist í™œìš©
    def _resolve_referee_conflict(self, conflicts: List[Dict],
                                  professors: List[ProfessorAgent],
                                  fixed_constants: Dict,
                                  session_num: int,
                                  deadlock_count: int) -> Tuple[List[Dict], int]:
        """
        Returns: (resolved_hallucinations, updated_deadlock_count)

        SUGGEST-01 Flow:
          deadlock_count < 2  â†’ professor defense â†’ (resolve or increment deadlock_count)
          deadlock_count >= 2 â†’ Force-Proceed: êµìˆ˜ íŒì •ìŠ¹, ë¡œê·¸ë§Œ ë‚¨ê¸°ê³  ì§„í–‰
        """
        resolved_hallucinations: List[Dict] = []

        for conflict in conflicts:
            print(f"\n  âš–ï¸  REFEREE CONFLICT DETECTED:")
            print(f"      Statement: {conflict['statement_signature'][:60]}â€¦")
            print(f"      Flagged by {len(conflict['flagged_by'])}/{conflict['total_referees']} referees")

            # ---- SUGGEST-01 : Force-Proceed ì²´í¬ ----
            if deadlock_count >= 2:
                print(f"      ğŸš© FORCE-PROCEED activated (deadlock_count={deadlock_count}). "
                      f"êµìˆ˜ íŒì •ìŠ¹ â€“ í• ë£¨ì‹œë„¤ì´ì…˜ í”Œë˜ê·¸ í•´ì œ, ë‹¤ìŒ ë…¼ë¦¬ë¡œ ì§„í–‰.")
                # êµìˆ˜ íŒì •ìŠ¹ â†’ hallucinationì„ resolved ëª©ë¡ì— ë„£ì§€ ì•ŠìŒ
                continue

            primary_detection = conflict['flagged_by'][0]
            hall = primary_detection['hallucination']
            # BUG-E : session í•„ë“œ ì¶”ê°€
            hall['session'] = session_num

            prof_idx = hall.get('professor_index', -1)
            if prof_idx < 0 or prof_idx >= len(professors):
                print(f"      âš ï¸ Invalid professor index, skipping")
                continue

            professor = professors[prof_idx]
            print(f"      â†’ Asking {professor.name} to provide evidenceâ€¦")

            defense = professor.defend_against_referee(
                challenged_statement=hall.get('statement', ''),
                referee_reasoning=hall.get('correct_info', ''),
                fixed_constants=fixed_constants
            )

            if defense.get('acknowledges_error', False):
                print(f"      âœ“ {professor.name} acknowledges error")
                resolved_hallucinations.append(hall)
            else:
                num_sources = len(defense.get('sources', []))
                print(f"      â†’ {professor.name} defends with {num_sources} sources")

                if num_sources >= 3:
                    print(f"      âœ“ Strong evidence â€“ hallucination flag removed")
                    # hallucination í•´ì œ â†’ ëª©ë¡ì— ì¶”ê°€í•˜ì§€ ì•ŠìŒ
                else:
                    # ì†ŒìŠ¤ ë¶€ì¡± + ValidationSpecialist ê°œì… ê¸ˆì§€ â†’
                    # hallucinationì„ ìœ ì§€í•˜ê³  deadlock_count ì¦ê°€
                    print(f"      âš–ï¸  Insufficient sources ({num_sources}/3). "
                          f"Flagging hallucination, incrementing deadlock count.")
                    hall['professor_defense_weak'] = True
                    hall['defense_sources_count'] = num_sources
                    resolved_hallucinations.append(hall)
                    deadlock_count += 1

        return resolved_hallucinations, deadlock_count

    # ------------------------------------------------------------------
    def _severity_score(self, hallucination: Dict) -> int:
        return {"critical": 4, "high": 3, "medium": 2, "low": 1}.get(
            hallucination.get('severity', 'low'), 1)

    def _detect_loop(self, recent_topics: List[str], window: int = 3) -> bool:
        if len(recent_topics) < window:
            return False
        all_kw: set = set()
        for topic in recent_topics[-window:]:
            kw = set(topic.lower().split())
            if len(all_kw.intersection(kw)) > 3:
                return True
            all_kw.update(kw)
        return False

    # ------------------------------------------------------------------
    # MAIN SIMULATION LOOP
    def run_learning_simulation(self,
                                proven_fact: str,
                                topic: str,
                                evidence_stages: List[List[str]],
                                fixed_constants: Dict = None,
                                total_sessions: int = 12,
                                max_turns_per_session: int = 5,
                                output_file: str = "results.json",
                                verbose: bool = False) -> Dict:

        print(f"\n{'=' * 70}")
        print(f"  PROVEN FACT-BASED LEARNING SIMULATION  v1.4.0")
        print(f"{'=' * 70}")
        print(f"  Topic    : {topic}")
        print(f"  Sessions : {total_sessions}")
        print(f"  Profs    : {self.num_professors}  |  Referees: {self.num_referees}")
        print(f"{'=' * 70}\n")

        self.fixed_constants = fixed_constants or {}
        self._create_personas(topic, proven_fact)

        constants_str = self._format_constants_string()
        if constants_str:
            for prof in self.professors:
                prof.inject_constants(constants_str)
            for ref in self.referees:
                ref.inject_constants(constants_str)

        stage_boundaries = self._determine_stage_boundaries(total_sessions, len(evidence_stages))
        print(f"ğŸ“Š Evidence Stage Boundaries: {stage_boundaries}\n")

        all_hallucinations: List[Dict] = []
        session_topics: List[str] = []
        self.confirmed_logic = []
        # â”€â”€ C-02: pending_logic ìŠ¤í…Œì´ì§• + consecutive_clean_count â”€â”€
        # ìŠ¹ê²© ê·œì¹™ (ì—°ì† 2íšŒ clean í•„ìˆ˜):
        #   clean ì„¸ì…˜  â†’ count += 1;  í˜„ì¬ ë…¼ë¦¬ë¥¼ pendingìœ¼ë¡œ ì €ì¥
        #               â†’ count >= 2 ì´ë©´ ì§ì „ pendingì„ confirmedë¡œ ìŠ¹ê²©
        #   hallucination ì„¸ì…˜ â†’ count = 0; pending íê¸°
        # ì‹œë®¬ë ˆì´ì…˜ ì¢…ë£Œ ì‹œ ë‚¨ì€ pendingì€ confirmedë¡œ ìŠ¹ê²© (ë§ˆì§€ë§‰ ì„¸ì…˜ ë³´í˜¸)
        pending_logic: Optional[Dict] = None
        self.consecutive_clean_count = 0

        # â”€â”€ SESSION ë£¨í”„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        for session_num in range(1, total_sessions + 1):
            print(f"\n{'â”€' * 70}")
            print(f"SESSION {session_num}/{total_sessions}")
            print(f"{'â”€' * 70}")

            current_stage = self._get_current_stage(session_num, stage_boundaries)
            available_evidence = evidence_stages[current_stage - 1]
            print(f"ğŸ“ Evidence Stage: {current_stage}/4  |  Evidence items: {len(available_evidence)}")

            # --- stage transition ---
            if session_num > 1:
                prev_stage = self._get_current_stage(session_num - 1, stage_boundaries)
                if current_stage != prev_stage:
                    print(f"\nğŸ”„ STAGE TRANSITION: {prev_stage} â†’ {current_stage}")
                    for prof in self.professors:
                        prof.update_stage(current_stage)

            # --- referee reset + SUGGEST-06 stage ì¦ê±° ì—…ë°ì´íŠ¸ ---
            for referee in self.referees:
                referee.update_current_stage(current_stage, available_evidence)
                if session_num in referee.reset_schedule:
                    referee.reset_cognitive_state()

            # --- SUGGEST-03 : studentì—ê²Œ confirmed_logic ì „ë‹¬ ---
            if self.confirmed_logic:
                self.student.update_confirmed_logic(self.confirmed_logic)

            context = f"Topic: {topic}\nProven Fact: {proven_fact}\nCurrent Stage: {current_stage}"

            # â”€â”€ TURN ë£¨í”„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            turn_count = 0
            session_complete = False
            session_hallucinations: List[Dict] = []
            deadlock_count = 0   # SUGGEST-01 : ì„¸ì…˜ ë‹¹ êµì°© íšŸìˆ˜ ì¶”ì 
            professor_responses: List[str] = []   # ì´ì „ í„´ êµìˆ˜ ì‘ë‹µ (í•™ìƒì—ê²Œ ì „ë‹¬ìš©)

            while not session_complete and turn_count < max_turns_per_session:
                turn_count += 1
                print(f"\n  Turn {turn_count}:")

                if self._detect_loop(session_topics):
                    print(f"  âš ï¸  Loop detected â€“ forcing new angleâ€¦")
                    context += "\n[Force new angle â€“ avoid repetition]"

                # --- Student question ---
                student_errors = [
                    h['statement'] for h in session_hallucinations
                    if not h.get('professors_caught', True)
                ]
                # Turn 1: êµìˆ˜ ì‘ë‹µ ì•„ì§ ì—†ìŒ â†’ contextë§Œ ì „ë‹¬
                # Turn 2+: ì´ì „ í„´ êµìˆ˜ ì‘ë‹µì„ í•™ìƒì—ê²Œ ì „ë‹¬í•˜ì—¬ í† ë¡  ì—°ì†ì„± ìœ ì§€
                prev_prof_text = ""
                if turn_count > 1 and professor_responses:
                    prev_prof_text = "\n\n".join(
                        f"Professor {i+1}:\n{resp}"
                        for i, resp in enumerate(professor_responses)
                    )
                student_question = self.student.ask_question(
                    professors_explanation=prev_prof_text,
                    context=context,
                    previous_errors=student_errors or None,
                    confirmed_logic=self.confirmed_logic   # SUGGEST-03
                )
                if verbose:
                    print(f"\n  ğŸ“ Student: {student_question[:200]}â€¦")

                session_topics.append(' '.join(student_question.split()[:10]))

                # --- Professor responses (rotated order) ---
                order = list(range(len(self.professors)))
                order = order[turn_count % len(order):] + order[:turn_count % len(order)]

                consistency_reminder = (
                    "âš ï¸ CONSISTENCY CHECK:\n"
                    "Review your previous arguments to ensure you're not contradicting established points.\n"
                    "Build upon, don't undermine, previous reasoning.\n"
                ) if self.professors[0].previous_arguments else ""

                professor_responses = []   # ì´ë²ˆ í„´ êµìˆ˜ ì‘ë‹µ ì´ˆê¸°í™”
                for idx in order:
                    prof = self.professors[idx]
                    resp = prof.teach(
                        student_question=student_question,
                        context=context,
                        available_evidence=available_evidence,
                        consistency_reminder=consistency_reminder
                    )
                    professor_responses.append(resp)
                    if verbose:
                        print(f"\n  ğŸ“š {prof.name}: {resp[:200]}â€¦")

                # --- Referee verification ---
                all_referee_results: List[Dict] = []
                for referee in self.referees:
                    result = referee.verify_statements(
                        professors_responses=professor_responses,
                        student_question=student_question,
                        session_num=session_num,
                        fixed_constants=self.fixed_constants,
                        current_stage=current_stage,                    # SUGGEST-02
                        current_stage_evidence=available_evidence       # SUGGEST-02
                    )
                    all_referee_results.append(result)

                # --- Conflict detection & resolution ---
                has_conflict, conflicts = self._detect_referee_conflict(all_referee_results)

                # BUG-D : record_exchangeëŠ” í•­ìƒ ì‹¤í–‰ (continue ì „ì—)
                self.recorder.record_exchange(
                    session_num=session_num,
                    exchange_num=turn_count,
                    student_question=student_question,
                    professors_responses=professor_responses,
                    referee_results=all_referee_results,
                    context=context
                )

                if has_conflict:
                    print(f"\n  âš–ï¸  REFEREE CONFLICT: {len(conflicts)} disagreement(s)")

                    resolved, deadlock_count = self._resolve_referee_conflict(
                        conflicts=conflicts,
                        professors=self.professors,
                        fixed_constants=self.fixed_constants,
                        session_num=session_num,
                        deadlock_count=deadlock_count
                    )
                    session_hallucinations.extend(resolved)

                    # SUGGEST-01 : Force-Proceed í›„ ì„¸ì…˜ ì¢…ë£Œ
                    if deadlock_count >= 2:
                        print(f"  ğŸš© FORCE-PROCEED: êµìˆ˜ íŒì •ìŠ¹ìœ¼ë¡œ ì„¸ì…˜ ì¢…ë£Œ. ë‹¤ìŒ ë…¼ë¦¬ë¡œ ì§„í–‰.")
                        session_complete = True
                    elif turn_count >= max_turns_per_session:
                        print(f"  ğŸ›‘ Max turns reached after conflict resolution")
                        session_complete = True
                    # else: continue to next turn
                else:
                    # ì¶©ëŒ ì—†ìŒ â†’ ì •ìƒ ì¢…ë£Œ
                    for result in all_referee_results:
                        for h in result.get('professor_hallucinations', []):
                            h['session'] = session_num   # BUG-E
                            session_hallucinations.append(h)
                    session_complete = True

            # â”€â”€ SESSION ì¢…ë£Œ ì •ë¦¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            if session_hallucinations:
                print(f"\n  âš ï¸  Session {session_num}: {len(session_hallucinations)} hallucination(s)")
                all_hallucinations.extend(session_hallucinations)
                # C-02: í• ë£¨ì‹œë„¤ì´ì…˜ ë°œê²¬ â†’ ì¹´ìš´í„° ë¦¬ì…‹ + pending íê¸°
                self.consecutive_clean_count = 0
                if pending_logic is not None:
                    print(f"  ğŸ”’ Pending logic from Session {pending_logic['session']} "
                          f"discarded (hallucination detected â†’ count reset to 0)")
                    pending_logic = None
            else:
                print(f"\n  âœ… Session {session_num}: Clean (no hallucinations)")

                # C-02: ì—°ì† clean ì¹´ìš´í„° ì¦ê°€
                self.consecutive_clean_count += 1
                print(f"  ğŸ“Š consecutive_clean_count = {self.consecutive_clean_count}")

                # ì¹´ìš´í„° >= 2 ì´ê³  ì§ì „ pendingì´ ìˆìœ¼ë©´ â†’ confirmedë¡œ ìŠ¹ê²©
                if self.consecutive_clean_count >= 2 and pending_logic is not None:
                    self.confirmed_logic.append(pending_logic)
                    for referee in self.referees:
                        referee.add_confirmed_logic(pending_logic)
                    print(f"  âœ… Logic from Session {pending_logic['session']} "
                          f"promoted to confirmed (consecutive_clean_count={self.consecutive_clean_count} >= 2)")

                # í˜„ì¬ ì„¸ì…˜ì˜ ë…¼ë¦¬ â†’ pendingìœ¼ë¡œ ì €ì¥ (ì•„ì§ ìŠ¹ê²©ë˜ì§€ ì•ŠìŒ)
                pending_logic = {
                    "conclusion": (
                        f"Session {session_num} established valid reasoning about "
                        f"{topic} using Stage {current_stage} evidence"
                    ),
                    "evidence": available_evidence[:3],
                    "session": session_num
                }
                print(f"  â³ Logic from Session {session_num} staged as pending "
                      f"(awaiting next-session confirmation)")

            if turn_count >= max_turns_per_session and not session_complete:
                print(f"  â±ï¸  Session force-completed after {turn_count} turns")

        # â”€â”€ LOOP ì¢…ë£Œ í›„: ë§ˆì§€ë§‰ pendingì´ ë‚¨ì•„ìˆìœ¼ë©´ confirmedë¡œ ìŠ¹ê²© â”€â”€
        if pending_logic is not None:
            self.confirmed_logic.append(pending_logic)
            for referee in self.referees:
                referee.add_confirmed_logic(pending_logic)
            print(f"  âœ… Final pending logic from Session {pending_logic['session']} "
                  f"promoted to confirmed (end-of-simulation)")

        # â”€â”€ FINAL VALIDATION â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        print(f"\n{'=' * 70}")
        print(f"  FINAL VALIDATION")
        print(f"{'=' * 70}\n")

        hallucination_summary = {
            "total": len(all_hallucinations),
            "by_severity": {
                sev: len([h for h in all_hallucinations if h.get('severity') == sev])
                for sev in ('critical', 'high', 'medium', 'low')
            },
            "rate": len(all_hallucinations) / max(1, total_sessions * max_turns_per_session)
        }

        final_audit = self.validator.audit_simulation(
            all_records=self.recorder.records,
            hallucination_summary=hallucination_summary
        )

        sft_data = self.recorder.generate_sft_data()

        results = {
            "metadata": {
                "topic": topic,
                "proven_fact": proven_fact,
                "total_sessions": total_sessions,
                "num_professors": self.num_professors,
                "num_referees": self.num_referees,
                "timestamp": datetime.now().isoformat(),
                "api_provider": self.api_provider,
                "version": "1.3.0"
            },
            "fixed_constants": self.fixed_constants,
            "stage_boundaries": stage_boundaries,
            "confirmed_logic": self.confirmed_logic,
            "pending_logic": pending_logic,   # C-02: í˜„ì¬ ìŠ¤í…Œì´ì§„ ë…¼ë¦¬ (None ë˜ëŠ” Dict)
            "all_records": self.recorder.records,
            "hallucinations": all_hallucinations,
            "hallucination_summary": hallucination_summary,
            "final_audit": final_audit,
            "sft_data": sft_data
        }

        # --- Save ---
        # Ensure output directory exists
        output_dir = os.path.dirname(output_file)
        if output_dir and not os.path.exists(output_dir):
            os.makedirs(output_dir, exist_ok=True)

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)

        sft_file = output_file.replace('.json', '.jsonl')
        with open(sft_file, 'w', encoding='utf-8') as f:
            for item in sft_data:
                f.write(json.dumps(item, ensure_ascii=False) + '\n')

        print(f"\n{'=' * 70}")
        print(f"  SIMULATION COMPLETE")
        print(f"{'=' * 70}")
        print(f"  Hallucinations   : {hallucination_summary['total']} "
              f"(rate {hallucination_summary['rate']:.2%})")
        print(f"  SFT examples     : {len(sft_data)}")
        print(f"  Confirmed Logic  : {len(self.confirmed_logic)} nodes")
        print(f"  Results          : {output_file}")
        print(f"  SFT data         : {sft_file}")
        print(f"{'=' * 70}\n")

        return results


# ===========================================================================
# CLI entry point
# ===========================================================================
def main():
    import argparse

    parser = argparse.ArgumentParser(description='Run Proven Fact-Based Algorithm v1.4.0')
    parser.add_argument('--api', choices=['anthropic', 'openai'], default='anthropic')
    parser.add_argument('--sessions', type=int, default=12)
    parser.add_argument('--referees', type=int, choices=[2, 3], default=2)
    parser.add_argument('--verbose', action='store_true')
    args = parser.parse_args()

    system = ProvenFactSystem(api_provider=args.api, num_referees=args.referees)

    example_config = {
        "proven_fact": "The Earth is approximately spherical with a circumference of 40,075 km at the equator.",
        "topic": "The Spherical Shape of Earth",
        "fixed_constants": {
            "Earth_circumference_km": 40075,
            "Earth_diameter_km": 12742,
            "Greek_stadium_meters": 185
        },
        "evidence_stages": [
            ["Ships disappear hull-first over horizon"],
            ["Eratosthenes measured Earth's circumference using shadows"],
            ["Magellan's circumnavigation completed"],
            ["Satellite photos from space"]
        ]
    }

    system.run_learning_simulation(
        proven_fact=example_config["proven_fact"],
        topic=example_config["topic"],
        evidence_stages=example_config["evidence_stages"],
        fixed_constants=example_config["fixed_constants"],
        total_sessions=args.sessions,
        verbose=args.verbose
    )


if __name__ == "__main__":
    main()
